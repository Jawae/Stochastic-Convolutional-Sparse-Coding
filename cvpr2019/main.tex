\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{wrapfig}
\usepackage{subcaption}

\usepackage{caption}
\captionsetup[table]{position=bottom}

\usepackage{array}
\usepackage{epstopdf}
\usepackage{cuted}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi

\input{macro}
\begin{document}

%%%%%%%%% TITLE
\title{Stochastic Convolutional Sparse Coding}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
  State-of-the-art methods for Convolutional Sparse Coding usually
  employ Fourier-domain solvers in order to speed up the convolution
  operators. However, this approach is not without shortcomings. For
  example, Fourier-domain representations implicitly assume circular
  boundary conditions and make it hard to fully exploit the sparsity
  of the problem as well as the small spatial support of the filters.
  
  %% The minimization problems formulated in                               %%
  %% (CSC) have been solved in frequency domain by modern approaches owing %%
  %% to the improved computing efficiency. However, solving the problem in %%
  %% frequency domain automatically assumes circular boundary conditions,  %%
  %% and also it is restricted by imposing modern optimization strategies  %%
  %% for this specific problem.                                            %%

  In this work, we propose a novel stochastic spatial-domain solver,
  in which a randomized subsampling strategy is introduced during the
  learning sparse codes. Afterwards, we extend the proposed strategy
  in conjunction with online learning, scaling the CSC model up to
  very large sample sizes. In both cases, we show experimentally that
  the proposed subsampling strategy, with a reasonable selection of
  the subsampling rate, outperforms the state-of-the-art
  frequency-domain solvers in terms of execution time without losing
  the learning quality. Finally, we evaluate the effectiveness of the
  over-complete dictionary learned from large-scale datasets that has
  not been studied by precedent CSC work, which demonstrates an
  improved sparse representation of the natural images on account of
  more abundant learned image features.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{Introduction}

\input{CSCmodel}

\input{SCSCmodel}

\input{Results}

\input{Conclusion}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\clearpage
\appendix

\input{supplement}

\end{document}



% --- DO NOT DELETE ---
% Local Variables:
% mode: latex
% mode: flyspell
% mode: TeX-PDF
% End:

