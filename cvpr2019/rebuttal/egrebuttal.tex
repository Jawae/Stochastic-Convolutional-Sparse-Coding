\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\input{macro}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{3722} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Author Response for Stochastic Convolutional Sparse Coding}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}

\underline{General comments}

\textbf{Convergence:} This work is application-oriented addressing limitations in existing methods, and explores new directions tackling the problem and achieves improved learning efficiency. The empirical convergence has been validated on multiple datasets, and the demonstrated efficiency offers broader potential research directions on CSC model those fit well with CVPR interests. We agree a theoretical analysis is desired for the proposed method, however, judging the work \textbf{only} by its theoretical guarantee is biased.

%The work should not only be valued by its theoretical guarantee, but also its experimental performance and contributions to this field that fit well with CVPR venue.

\underline{Reviewer 1}

\textbf{Novelty:}
It should be emphasized that the proposed method is the first spatial-domain solver for CSC problem that outperforms existing Fourier-domain solvers in terms of time both in batch mode and online mode. Solving CSC problem in spatial domain brings higher capabilities of handling arbitrary boundary conditions, additional regularization terms those can not be handled in Fourier domain (also see response to reviewer 3: \textbf{comparisons}), offering CSC model higher feasibility to wider applications.

\textbf{Simplicity:} We believe an algorithm should be judged by its effectiveness and efficiency, not on how complicated it is. Simplicity is a virtue, and simplifying complicated problems is also a key motivation for conducting research.

%\textbf{Algorithm:}
%It is unfair to value an algorithm by its complexity, while it should be valued by its effectiveness and efficiency. Easing complicated problems is also a key motivation for conducting researches.

\underline{Reviewer 2}

\textbf{Specific questions:}

1. $\Filter_k \in \mathbb{R}^{D \times D}$ is a Toeplitz matrix for filter $\filter_k \in \mathbb{R}^{M}$,
%\begin{equation}\label{toeplitz}
% \Filter_k =
% \begin{bmatrix}
%    \filter_{k,1} \\
%    \filter_{k,2} & \filter_{k,1}\\
%    \vdots        & \filter_{k,2} & \filter_{k,1}\\
%    \filter_{k,M} & \vdots        & \filter_{k,2}\\
%                  & \filter_{k,M} & \vdots       \\
%                  &               & \filter_{k,M} & \ddots\\
%                  &               &               &        & \ddots
%  \end{bmatrix}
%\end{equation}
\begin{equation}\label{toeplitz}
 \Filter_k =
 \begin{bmatrix}
    \filter_{k,1} \\
    \filter_{k,2} & \filter_{k,1}\\
    \vdots        & \filter_{k,2}\\
    \filter_{k,M} & \vdots       \\
                  & \filter_{k,M} & \ddots
  \end{bmatrix} \nonumber
\end{equation}
$\Filter = [\Filter_1, \dots, \Filter_K]$, therefore $\Filter$ has the size of $D \times DK$.

2. Problem (5) is solved according to all data. For notational simplicity, we omit the notation for data samples. In line 145, we declare the equations are applied to all training samples for batch mode, and in line 351 we emphasize that the equations in online mode only applies to a portion of the samples. We will make this more clear in revised version.

3. In order to deriving updating rule (8), we can expand equation (7) as:
%\begin{equation}
$\filter^t = \minimize{\filter} \frac{1}{2t} \filter^{\top} (\sum_{i=1}^{t}{(\Code^i)^{\top}\Code^i})\filter - \frac{1}{t}\filter^{\top} (\sum_{i=1}^{t}{(\Code^i)^{\top}\signal^i})$ . %\nonumber
%\end{equation}
Let $\surC^t = \frac{1}{t}\sum_{i=1}^{t}{(\Code^i)^{\top}\Code^i}$ and $\surB^t = \frac{1}{t} \sum_{i=1}^{t}{(\Code^i)^{\top}\signal^i}$, then we obtain equation (9), and the rule (8) is obvious for a recursive computation.

\underline{Reviewer 3}

\textbf{Sparsity:}
We have demonstrated the sparsity in Figure 4 of supplementary material, which states that on average the codes has $0.18\%$ non-zero elements for 100 filters. It also shows that using over-complete dictionary leads to $8\% - 10\%$ reduction on the non-zero elements and achieves significantly improved representation ability.

\textbf{Connections:}
The connections between section 2 and the proposed method can be understood from 2 aspects. The first two points in section 2 contributes to the first motivation. CSC model is an overparameterized model, and the sparsity property of the codes can hardly be exploited if solving the problem in Fourier domain. The third point accounts for the second motivation that the dimension size of updating dictionary step is $D$ when solving it in Fourier domain, instead of $M$ in spatial domain ($M \ll D$).

\textbf{PSNR:}
PSNR is the peak signal-to-noise ratio, measuring the difference between the reconstructed signal and the original one. We will explain it in the revised version.

\textbf{Parameter:}
The parameter sensitivity in CSC model has been extensively studied in Wohlberg et al. 2016. If the reviewer asks for, we will add it in supplement.

\textbf{Comparisons:}
The comparisons with (3)(Choudhury et al. ICCV 2017) and (4)(Degraux et al. ICIP 2017) are not applicable. (3) focuses on memory
efficiency by splitting a large problem into smaller chunks, which can be solved sequentially on one node or in parallel on multiple
nodes. This splitting however introduces additional computational overhead compared to Heide et al, which we compare against. (4) formulates the multimodal image reconstruction into the CSC model, and uses the basic coordinate descent algorithm to solve the problem in spatial domain (which are known to have poor runtime performance) because the multimodal imaging model is not convolution based. We emphasize that our proposed strategy can be perfectly aligned with this types of problem and achieve roughly one magnitude speedup (also see response to reviewer 1).
 
% because (3) distributes the data to multiple machines to ease the memory issue, while it stills has the heavy computational burden. The proposed single-core program is fair to compare with single-core implementations. 

To achieve the final convergence, (2)(Papyan et al. ICCV 2017) requires $1.5 \times$ runtime over the compared Fourier-domain solver (Heide et al.), namely ours SBCSC can run $3 \times$ faster than (2) ((2) needs over 300 iterations to converge while Heide et al. and ours need only 12-14 iterations). The runtime of ours SOCSC is \textbf{comparable} to the reported results in (1)(Wang et al. ICML 2018), roughly $70$ seconds to process the fruit and city dataset. \textbf{Notice that} (1) runs on GPUs and introduces base filters to represent the original filters, making the problem more complicated. These additional comparisons \textbf{affirm the superiority} of the proposed method. All the comparisons and discussions will be added.

We emphasize that none of the precedent work represent the importance of the over-complete dictionary learned in CSC model, and we have shown that they play an important role in image reconstruction tasks.

%{\small
%\bibliographystyle{ieee}
%\bibliography{egbib}
%}

\end{document}
