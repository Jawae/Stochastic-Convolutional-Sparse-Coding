\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{jas2017learning}
\citation{peter2017sparse}
\citation{heide2015fast}
\citation{gu2015convolutional}
\citation{serrano2016convolutional}
\citation{choudhury2017consensus}
\citation{bibi2017high}
\citation{lecun1998gradient}
\citation{kavukcuoglu2010learning}
\citation{krizhevsky2012imagenet}
\citation{zeiler2010deconvolutional}
\citation{boyd2011distributed}
\citation{bristow2013fast}
\citation{heide2015fast}
\citation{wohlberg2016efficient}
\citation{choudhury2017consensus}
\citation{shalev2012online}
\citation{bottou1998online}
\citation{bousquet2008tradeoffs}
\citation{mairal2009online}
\citation{mairal2010online}
\citation{mensch2016dictionary}
\citation{liu-2018-first}
\citation{wang2018scalable}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{brf}{\backcite{jas2017learning,peter2017sparse}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{heide2015fast}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{gu2015convolutional}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{serrano2016convolutional}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{choudhury2017consensus,bibi2017high}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{lecun1998gradient,kavukcuoglu2010learning,krizhevsky2012imagenet}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{zeiler2010deconvolutional}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{boyd2011distributed}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{bristow2013fast,heide2015fast,wohlberg2016efficient,choudhury2017consensus}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{shalev2012online}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{bottou1998online}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{bousquet2008tradeoffs}{{1}{1}{section.1}}}
\citation{bristow2013fast}
\citation{heide2015fast}
\citation{wohlberg2016efficient}
\@writefile{brf}{\backcite{mairal2009online,mairal2010online}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{mensch2016dictionary}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{liu-2018-first}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{wang2018scalable}{{2}{1}{section.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Convolutional Sparse Coding (CSC)}{2}{section.2}}
\newlabel{eq:CSCmodel}{{1}{2}{\hskip -1em.~Convolutional Sparse Coding (CSC)}{equation.2.1}{}}
\@writefile{brf}{\backcite{bristow2013fast,heide2015fast,wohlberg2016efficient}{{2}{2}{equation.2.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Stochastic Convolutional Sparse Coding}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}The Model}{2}{subsection.3.1}}
\newlabel{eq:updatingFilter}{{2}{2}{\hskip -1em.~The Model}{equation.3.2}{}}
\newlabel{eq:updatingCode}{{3}{2}{\hskip -1em.~The Model}{equation.3.3}{}}
\citation{mensch2016dictionary}
\citation{reddi2016stochastic}
\citation{pmlr-v80-kerdreux18a}
\newlabel{eq:updatingFilter}{{4}{3}{\hskip -1em.~The Model}{equation.3.4}{}}
\@writefile{brf}{\backcite{mensch2016dictionary}{{3}{3.1}{equation.3.4}}}
\@writefile{brf}{\backcite{reddi2016stochastic,pmlr-v80-kerdreux18a}{{3}{3.1}{equation.3.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Stochastic Batch CSC (SBCSC)}{3}{subsection.3.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces SBCSC\relax }}{3}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{algo:SBCSC}{{1}{3}{SBCSC\relax }{algorithm.1}{}}
\citation{mairal2009online}
\citation{mairal2010online}
\citation{zeiler2010deconvolutional}
\citation{deng2009imagenet}
\citation{zeiler2010deconvolutional}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{heide2015fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Stochastic Online CSC (SOCSC)}{4}{subsection.3.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces SOCSC\relax }}{4}{algorithm.2}}
\newlabel{algo:SOCSC}{{2}{4}{SOCSC\relax }{algorithm.2}{}}
\newlabel{eq:updatingCodeOnline}{{5}{4}{\hskip -1em.~Stochastic Online CSC (SOCSC)}{equation.3.5}{}}
\@writefile{brf}{\backcite{mairal2009online,mairal2010online}{{4}{3.3}{equation.3.6}}}
\newlabel{eq:updateSur}{{7}{4}{\hskip -1em.~Stochastic Online CSC (SOCSC)}{equation.3.7}{}}
\newlabel{eq:updatingFilterOnline}{{8}{4}{\hskip -1em.~Stochastic Online CSC (SOCSC)}{equation.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.\nobreakspace  {}Complexity Analysis}{4}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Results}{4}{section.4}}
\newlabel{sec:result}{{4}{4}{\hskip -1em.~Results}{section.4}{}}
\@writefile{brf}{\backcite{zeiler2010deconvolutional}{{4}{4}{section.4}}}
\@writefile{brf}{\backcite{deng2009imagenet}{{4}{4}{section.4}}}
\@writefile{brf}{\backcite{zeiler2010deconvolutional,heide2015fast}{{4}{4}{section.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Subsampling Strategy}{4}{subsection.4.1}}
\@writefile{brf}{\backcite{heide2015fast}{{4}{4.1}{subsection.4.1}}}
\citation{wohlberg2016efficient}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{liu-2018-first}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Top: Convergence comparison between the-state-of-art method\nobreakspace  {}\cite  {heide2015fast} and the proposed method with different subsampling rate, all of which on performed on fruit dataset. Convergence is evaluated by monitoring the objective value of Eq.\nobreakspace  {}\ref  {eq:CSCmodel} on training images versus iterations and time, respectively. Bottom: Learned filters by the proposed method with $p=0.1$ and the comparable method. In these represented learned filters, our method learns more smooth Gabor-like filters and less number of noise-like filters with the same $\lambda $. Beyond this, it runs faster with regard to each iteration and shows better convergence behavior.\relax }}{5}{figure.caption.1}}
\@writefile{brf}{\backcite{heide2015fast}{{5}{1}{figure.caption.1}}}
\newlabel{fig:subsampleResult}{{1}{5}{Top: Convergence comparison between the-state-of-art method~\cite {heide2015fast} and the proposed method with different subsampling rate, all of which on performed on fruit dataset. Convergence is evaluated by monitoring the objective value of Eq.~\ref {eq:CSCmodel} on training images versus iterations and time, respectively. Bottom: Learned filters by the proposed method with $p=0.1$ and the comparable method. In these represented learned filters, our method learns more smooth Gabor-like filters and less number of noise-like filters with the same $\lambda $. Beyond this, it runs faster with regard to each iteration and shows better convergence behavior.\relax }{figure.caption.1}{}}
\@writefile{brf}{\backcite{wohlberg2016efficient}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{heide2015fast}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{heide2015fast}{{5}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Online Learning}{5}{subsection.4.2}}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{liu-2018-first}
\@writefile{brf}{\backcite{heide2015fast}{{6}{\caption@xref {??}{ on input line 47}}{figure.caption.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Numerical comparisons of the reconstruction quality obtained from the presented filters and its comparison. The reconstructions are performed on $50\%$ randomly observed images, with $\lambda = 0.4$ and $50$ ADMM iterations for both cases. Obtained PSNR values are averaged on 5 trials. Note that none of the testing images are in the training sets.\relax }}{6}{figure.caption.2}}
\newlabel{fig:PSNRrecon}{{2}{6}{Numerical comparisons of the reconstruction quality obtained from the presented filters and its comparison. The reconstructions are performed on $50\%$ randomly observed images, with $\lambda = 0.4$ and $50$ ADMM iterations for both cases. Obtained PSNR values are averaged on 5 trials. Note that none of the testing images are in the training sets.\relax }{figure.caption.2}{}}
\@writefile{brf}{\backcite{liu-2018-first}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{liu-2018-first}{{6}{4.2}{figure.caption.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The experiments are performed on fruit dataset, and each iteration randomly choose one samples from the training datasets. Top: Convergence of the test set objectives (objective value of Eq.\nobreakspace  {}\ref  {eq:CSCmodel} on testing datasets) for our method (SOCSC) and the state-of-the-art online approach\nobreakspace  {}\cite  {liu-2018-first}. Bottom: Testing PSNR with respect to execution time. While the quality of the output is comparable, our method achieves $6 \times $ speedup.\relax }}{6}{figure.caption.3}}
\@writefile{brf}{\backcite{liu-2018-first}{{6}{3}{figure.caption.3}}}
\newlabel{fig:onlineSmall}{{3}{6}{The experiments are performed on fruit dataset, and each iteration randomly choose one samples from the training datasets. Top: Convergence of the test set objectives (objective value of Eq.~\ref {eq:CSCmodel} on testing datasets) for our method (SOCSC) and the state-of-the-art online approach~\cite {liu-2018-first}. Bottom: Testing PSNR with respect to execution time. While the quality of the output is comparable, our method achieves $6 \times $ speedup.\relax }{figure.caption.3}{}}
\citation{Takac2013}
\citation{PCDM}
\citation{SCSG}
\citation{liu-2018-first}
\citation{liu-2018-first}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Filters learned from 1000 images by our method (SOCSC) and the state-of-the-art online method\nobreakspace  {}\cite  {liu-2018-first}, and their corresponding reconstruction quality using the same hyperparameter settings as in Fig.\nobreakspace  {}\ref  {fig:PSNRrecon}. (a) The under-complete dictionary ($11 \times 11 \times 100$) learned by\nobreakspace  {}\cite  {liu-2018-first}; (b) The under-complete dictionary ($11 \times 11 \times 100$) learned by SOCSC. (c) The over-complete dictionary ($11 \times 11 \times 400$) learned by SOCSC. These under-complete dictionaries, mainly composed of Gabor-like filters, can be seen as a subset of the represented over-complete dictionary, which contains a number of extra low contrast image features.\relax }}{7}{figure.caption.4}}
\@writefile{brf}{\backcite{liu-2018-first}{{7}{4}{figure.caption.4}}}
\@writefile{brf}{\backcite{liu-2018-first}{{7}{4}{figure.caption.4}}}
\newlabel{fig:overCompleteDic}{{4}{7}{Filters learned from 1000 images by our method (SOCSC) and the state-of-the-art online method~\cite {liu-2018-first}, and their corresponding reconstruction quality using the same hyperparameter settings as in Fig.~\ref {fig:PSNRrecon}. (a) The under-complete dictionary ($11 \times 11 \times 100$) learned by~\cite {liu-2018-first}; (b) The under-complete dictionary ($11 \times 11 \times 100$) learned by SOCSC. (c) The over-complete dictionary ($11 \times 11 \times 400$) learned by SOCSC. These under-complete dictionaries, mainly composed of Gabor-like filters, can be seen as a subset of the represented over-complete dictionary, which contains a number of extra low contrast image features.\relax }{figure.caption.4}{}}
\@writefile{brf}{\backcite{Takac2013, PCDM, SCSG}{{7}{4.2}{figure.caption.4}}}
\citation{johnson2017stingycd}
\citation{ghaoui2012Swfe}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{bibi2017high}{1}
\bibcite{bottou1998online}{2}
\bibcite{bousquet2008tradeoffs}{3}
\bibcite{boyd2011distributed}{4}
\bibcite{bristow2013fast}{5}
\bibcite{choudhury2017consensus}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Top: Testing PSNR for the comparable method\nobreakspace  {}\cite  {liu-2018-first} with $K=100$, and our method (SOCSC) with $K=100$ and $K=400$, respectively. Every iteration draws a single image from those 1000 image patches. Bottom: Testing PSNR for SOCSC ($K=400$) with varying values of $\eta $. The learned filters are examined on the test sets every $2^i$ iterations and also at the last iteration, where $i=0,1,\dots  $. Note that all the results are generated by a single-core program.\relax }}{8}{figure.caption.5}}
\@writefile{brf}{\backcite{liu-2018-first}{{8}{5}{figure.caption.5}}}
\newlabel{fig:overComDicAndMinibatch}{{5}{8}{Top: Testing PSNR for the comparable method~\cite {liu-2018-first} with $K=100$, and our method (SOCSC) with $K=100$ and $K=400$, respectively. Every iteration draws a single image from those 1000 image patches. Bottom: Testing PSNR for SOCSC ($K=400$) with varying values of $\eta $. The learned filters are examined on the test sets every $2^i$ iterations and also at the last iteration, where $i=0,1,\dots $. Note that all the results are generated by a single-core program.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Conclusions}{8}{section.5}}
\@writefile{brf}{\backcite{johnson2017stingycd}{{8}{5}{section.5}}}
\@writefile{brf}{\backcite{ghaoui2012Swfe}{{8}{5}{section.5}}}
\bibcite{deng2009imagenet}{7}
\bibcite{ghaoui2012Swfe}{8}
\bibcite{gu2015convolutional}{9}
\bibcite{heide2015fast}{10}
\bibcite{jas2017learning}{11}
\bibcite{johnson2017stingycd}{12}
\bibcite{kavukcuoglu2010learning}{13}
\bibcite{pmlr-v80-kerdreux18a}{14}
\bibcite{krizhevsky2012imagenet}{15}
\bibcite{lecun1998gradient}{16}
\bibcite{SCSG}{17}
\bibcite{liu-2018-first}{18}
\bibcite{mairal2009online}{19}
\bibcite{mairal2010online}{20}
\bibcite{mensch2016dictionary}{21}
\bibcite{peter2017sparse}{22}
\bibcite{reddi2016stochastic}{23}
\bibcite{PCDM}{24}
\bibcite{serrano2016convolutional}{25}
\bibcite{shalev2012online}{26}
\bibcite{Takac2013}{27}
\bibcite{wang2018scalable}{28}
\bibcite{wohlberg2016efficient}{29}
\bibcite{zeiler2010deconvolutional}{30}
\citation{heide2015fast}
\@writefile{toc}{\contentsline {section}{\numberline {A}\hskip -1em.\nobreakspace  {}Solvers for LASSO and QCQP}{10}{appendix.A}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces ADMM framework for solving LASSO\relax }}{10}{algorithm.3}}
\newlabel{algo:ADMMLasso}{{3}{10}{ADMM framework for solving LASSO\relax }{algorithm.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Projected Block Coordinate Descent for solving QCQP\relax }}{10}{algorithm.4}}
\newlabel{algo:BCDQCQP}{{4}{10}{Projected Block Coordinate Descent for solving QCQP\relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}\hskip -1em.\nobreakspace  {}Zooming in on the Filters}{10}{appendix.B}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Zoom-in view of the filters from Figure\nobreakspace  {}\ref  {fig:subsampleResult}.\relax }}{10}{figure.caption.7}}
\citation{liu-2018-first}
\citation{liu-2018-first}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{liu-2018-first}
\citation{heide2015fast}
\citation{heide2015fast}
\citation{heide2015fast}
\@writefile{toc}{\contentsline {section}{\numberline {C}\hskip -1em.\nobreakspace  {}Additional Experiments}{11}{appendix.C}}
\@writefile{brf}{\backcite{heide2015fast}{{11}{C}{appendix.C}}}
\@writefile{brf}{\backcite{liu-2018-first}{{11}{C}{figure.caption.9}}}
\@writefile{toc}{\contentsline {section}{\numberline {D}\hskip -1em.\nobreakspace  {}Over-complete Dictionary and Large Datasets}{11}{appendix.D}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Experimental results obtained on city dataset. Top: Convergence of the test set objectives for our method (SOCSC) and the state-of-the-art online approach\nobreakspace  {}\cite  {liu-2018-first}. Bottom: Testing PSNR with respect to execution time.\relax }}{11}{figure.caption.8}}
\@writefile{brf}{\backcite{liu-2018-first}{{11}{7}{figure.caption.8}}}
\newlabel{fig:onlineSmall-city}{{7}{11}{Experimental results obtained on city dataset. Top: Convergence of the test set objectives for our method (SOCSC) and the state-of-the-art online approach~\cite {liu-2018-first}. Bottom: Testing PSNR with respect to execution time.\relax }{figure.caption.8}{}}
\@writefile{brf}{\backcite{heide2015fast}{{12}{\caption@xref {??}{ on input line 111}}{figure.caption.9}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Experimental results obtained on the city dataset. Top: Convergence comparison between the-state-of-art batch method\nobreakspace  {}\cite  {heide2015fast} and SBCSC with different subsampling probability. Middle: Learned filters by SBCSC with $p=0.1$ and the comparable method. Even though these dictionaries look similar, our method learns more smooth filters. Compared to the learned filters in Fig.\ \ref  {fig:subsampleResult}, they have different representations of the dictionaries, where data-specific features are learned from handful training images. Bottom: Numerical comparisons of the reconstruction quality obtained by the presented filters.\relax }}{12}{figure.caption.9}}
\@writefile{brf}{\backcite{heide2015fast}{{12}{8}{figure.caption.9}}}
\newlabel{fig:subsampleResult-city}{{8}{12}{Experimental results obtained on the city dataset. Top: Convergence comparison between the-state-of-art batch method~\cite {heide2015fast} and SBCSC with different subsampling probability. Middle: Learned filters by SBCSC with $p=0.1$ and the comparable method. Even though these dictionaries look similar, our method learns more smooth filters. Compared to the learned filters in Fig.\ \ref {fig:subsampleResult}, they have different representations of the dictionaries, where data-specific features are learned from handful training images. Bottom: Numerical comparisons of the reconstruction quality obtained by the presented filters.\relax }{figure.caption.9}{}}
\@writefile{brf}{\backcite{heide2015fast}{{13}{\caption@xref {??}{ on input line 142}}{figure.caption.10}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Visual and numerical comparisons between the learned over-complete dictionaries by batch-mode algorithm and by online-mode algorithm. Top: Over-complete dictionary learned by batch CSC model\nobreakspace  {}\cite  {heide2015fast} on small dataset, and proposed online CSC model (SOCSC) on large dataset. Bottom: Respective reconstruction quality for these two over-complete dictionaries.\relax }}{13}{figure.caption.10}}
\@writefile{brf}{\backcite{heide2015fast}{{13}{9}{figure.caption.10}}}
\newlabel{fig:overCompleteDic-dataset}{{9}{13}{Visual and numerical comparisons between the learned over-complete dictionaries by batch-mode algorithm and by online-mode algorithm. Top: Over-complete dictionary learned by batch CSC model~\cite {heide2015fast} on small dataset, and proposed online CSC model (SOCSC) on large dataset. Bottom: Respective reconstruction quality for these two over-complete dictionaries.\relax }{figure.caption.10}{}}
