\section{Convolutional Sparse Coding (CSC)}
The dictionary learning problem for CSC problem has the form
\begin{equation}\label{eq:CSCmodel}
\begin{split}
    \mini{\filter,\code} & \frac{1}{2}\|\signal - \sum_{k=1}^{K} \filter_k * \code_k \|_2^2 + \lambda \sum_{k=1}^{K}\| \code_k \|_1 \\
    \text{subject to} & ~ \|\filter_k\|^2_2 \leq 1 ~~ \forall k \in \{1,\dots,K\},
\end{split}
\end{equation}
where $\signal \in \mathbb{R}^D$ is a $D$-dimensional signal or a
vectorized image\footnote{In this manuscript, we work on 2D images.},
$\filter_k \in \mathbb{R}^M$ is the $k$-th dictionary, $\code_k\in
\mathbb{R}^D$ is the sparse code associated with that dictionary,
$\lambda>0$ is a sparsity inducing penalty parameter, $K$ is the
number of dictionary filters, and $*$ is the convolution operator. The
above model will be applied to all the training images
$\signal\in\mathbb{X}$.

Most recent CSC algorithms exploit Parseval's theorem and introduce
two slack variables to separate the non-smooth $L_1$ penalty term and
the $L_2$ constraints, making it feasible to efficiently compute the
latter in the frequency domain. Furthermore, the whole
Problem~\eqref{eq:CSCmodel} can be split into alternating subproblems
for updating $\code$ and $\filter$, which are jointly solved by
coordinate
descent~\cite{bristow2013fast,heide2015fast,wohlberg2016efficient}. This
approach suffers from several issues:

\begin{itemize}
  \item While CSC overcomes the independence assumption held in
    patch-based learning algorithms, far more variables ($K$ times
    more) are introduced to represent a single image to compensate for
    this. This creates more severe memory and computational burdens.

  \item We observe through experiments that the vast majority of the
    entries of the reconstructed sparse codes do not provide useful
    information about the represented image. For $K=100$, 99.5\%
    entries are not informative. This indicates that the subproblem
    for updating $\code$ solves a highly sparse LASSO
    problem. Transforming the problem into frequency domain imposes
    restrictions on exploiting this sparsity.
    
  \item While prior work shows its efficiency in solving the CSC
    problem in the frequency domain, this is only applicable for
    updating $\code$, and does not hold for updating $\filter$. The
    dictionary filters usually have much smaller spatial support than
    the dimension size of the sparse codes ($M \ll D$). However, in
    order to tackle the problem in the frequency domain, it is
    necessary to process the $\filter$-subproblem over the full
    support of the sparse codes, and then project the results onto the
    much smaller spatial support of the filters.
\end{itemize}


% --- DO NOT DELETE ---
% Local Variables:
% mode: latex
% mode: flyspell
% mode: TeX-PDF
% End:

